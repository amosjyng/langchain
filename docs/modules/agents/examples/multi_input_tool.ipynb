{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87455ddb",
   "metadata": {},
   "source": [
    "# Multi Input Tools\n",
    "\n",
    "This notebook shows how to use a tool that requires multiple inputs with an agent.\n",
    "\n",
    "The difficulty in doing so comes from the fact that an agent decides it's next step from a language model, which outputs a string. So if that step requires multiple inputs, they need to either be inputted one at a time, or else parsed from a single string. The first currently supported way to do this is write a smaller wrapper function that parses that a string into multiple inputs.\n",
    "\n",
    "For a concrete example, let's work on giving an agent access to a multiplication function, which takes as input two integers. In order to use this, we will tell the agent to generate the \"Action Input\" as a comma separated list of length two. We will then write a thin wrapper that takes a string, splits it into two around a comma, and passes both parsed sides as integers to the multiplication function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "291149b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b6bead",
   "metadata": {},
   "source": [
    "Here is the multiplication function, as well as a wrapper to parse a string as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b82020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplier(a, b):\n",
    "    return a * b\n",
    "\n",
    "def parsing_multiplier(string):\n",
    "    a, b = string.split(\",\")\n",
    "    return multiplier(int(a), int(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db1d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Multiplier\",\n",
    "        func=parsing_multiplier,\n",
    "        description=\"useful for when you need to multiply two numbers together. The input to this tool should be a comma separated list of numbers of length two, representing the two numbers you want to multiply together. For example, `1,2` would be the input if you wanted to multiply 1 by 2.\"\n",
    "    )\n",
    "]\n",
    "mrkl = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa25d0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to multiply two numbers\n",
      "Action: Multiplier\n",
      "Action Input: 3,4\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m12\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 3 times 4 is 12\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3 times 4 is 12'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrkl.run(\"What is 3 times 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2752b274",
   "metadata": {},
   "source": [
    "## Getting inputs one at a time\n",
    "\n",
    "The second supported way is to retrieve multiple inputs, one at a time, using `GetMultipleOutputsChain`. This does away with the need for parsing the single input string, which can get complicated if the output includes code or other lengthy text. However, it is more expensive because it requires a separate LLM request for every input.\n",
    "\n",
    "Here is the above multiplier example, using `GetMultipleOutputsChain` for a single run of the loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c857c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': ' 3', 'b': ' 4'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.multiple_outputs import GetMultipleOutputsChain\n",
    "\n",
    "def multiplier_str(a: str, b: str):\n",
    "    return int(a) * int(b)\n",
    "\n",
    "tool = Tool(\n",
    "    name=\"Multiplier\",\n",
    "    func=multiplier_str,\n",
    "    description=\"useful for when you need to multiply two numbers together\",\n",
    ")\n",
    "\n",
    "dummy_agent_prompt = f\"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tool.name}: {tool.description}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool.name}]\n",
    "<Action Inputs>: the inputs to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: What is 3 times 4\n",
    "Thought: I need to multiply two numbers\n",
    "Action: Multiplier\n",
    "\"\"\".lstrip()\n",
    "\n",
    "multiplier_inputs_chain = GetMultipleOutputsChain(\n",
    "    llm=llm,\n",
    "    prefix=dummy_agent_prompt,\n",
    "    variables={\n",
    "        \"a\": \"First number to multiply\",\n",
    "        \"b\": \"Second number to multiply\",\n",
    "    },\n",
    ")\n",
    "\n",
    "multiplier_inputs = multiplier_inputs_chain({})\n",
    "print(multiplier_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c29604",
   "metadata": {},
   "source": [
    "Now we can call the tool directly from the LLM outputs without the use of a wrapper function, so long as the tool takes in only strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d25e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.func(**multiplier_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1759ff90",
   "metadata": {},
   "source": [
    "As of now, the default `Agent` and `AgentExecutor` do not support inputs to tools in this manner. As such, to actually make use of the above tool, we'll have to implement our own custom `AgentExecutor`.\n",
    "\n",
    "## Customizing AgentExecutor to use multi-input tooling\n",
    "\n",
    "First, let's subclass `Tool` so that each tool can describe what variables it expects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8fc02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "from langchain.chains.multiple_outputs import VariableConfig\n",
    "\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class CustomTool(Tool):\n",
    "    variable_configs: List[VariableConfig]\n",
    "\n",
    "\n",
    "def read_file(filename):  # dummy read file function  \n",
    "    if filename.strip().strip('\"') == \"script.py\":\n",
    "        return \"\"\"File contents are:\n",
    "\n",
    "```\n",
    "words = [\"Hello\", \"World!\"]\n",
    "print(\" \".join(words))\n",
    "```\n",
    "\"\"\".lstrip()\n",
    "    return \"No such file exists\"\n",
    "        \n",
    "\n",
    "read_tool = CustomTool(\n",
    "    name=\"Read File\",\n",
    "    func=read_file,\n",
    "    variable_configs=[\n",
    "        VariableConfig(display=\"File to read\", output_key=\"filename\"),\n",
    "    ],\n",
    "    description=(\n",
    "        \"useful for when you need to read the contents of a file. The sole input \"\n",
    "        \"is the path to the file to be read.\"\n",
    "    ),\n",
    ")\n",
    "assert read_tool.variable_configs is not None\n",
    "\n",
    "\n",
    "def write_file(filename, contents):  # dummy write file function  \n",
    "    return \"File written successfully\"\n",
    "\n",
    "\n",
    "write_tool = CustomTool(\n",
    "    name=\"Write File\",\n",
    "    func=write_file,\n",
    "    variable_configs=[\n",
    "        VariableConfig(display=\"File to write\", output_key=\"filename\"),\n",
    "        VariableConfig.for_code(display=\"File contents\", output_key=\"contents\"),\n",
    "    ],\n",
    "    description=(\n",
    "        \"useful for when you need to read the contents of a file. The inputs are \"\n",
    "        \"the path to the file to write to, and the contents to write to that file. \"\n",
    "        \"Enclose the file contents with ```\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7344d3d1",
   "metadata": {},
   "source": [
    "Because we now have actions with varying numbers of inputs and varying names for each input, it's harder both for the LLM to fill out, and for us to parse, all of the tool and inputs in one go as we were previously doing. As such, let's make the loop consistent and simple with a dummy \"Finished\" tool to break out of the loop.\n",
    "\n",
    "(In reality, this is in a sense generalizing the concept of tool usage to the overarching concept of decision making. Now, \"answering the question\" or \"finishing the task\" becomes a first-class decision just as much as \"using a tool\" is, and \"tool input\" generalizes to \"information associated with the execution of this decision.\" This is not a \"dummy\" tool so much as it is a legitimate decision for the LLM to make.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3d60c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finished_fn() -> str:\n",
    "    return \"Dummy return\"\n",
    "\n",
    "\n",
    "finished_tool = CustomTool(\n",
    "    name=\"Finished\",\n",
    "    func=finished_fn,\n",
    "    variable_configs=[],\n",
    "    description=(\n",
    "        \"useful for when you have finished the requested task. There are no inputs.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c27f813",
   "metadata": {},
   "source": [
    "Then, let's subclass `AgentAction` so that the LLM acting as an agent can actually use each of these tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22c4772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from typing import Dict\n",
    "\n",
    "from langchain.schema import AgentAction\n",
    "from langchain.agents.step import StepOutput\n",
    "\n",
    "\n",
    "CustomAction = namedtuple(\"CustomAction\", AgentAction._fields + (\"tool_inputs\",))\n",
    "# tool_inputs: Dict[str, str]\n",
    "\n",
    "# test that we can construct a CustomAction successfully\n",
    "dummy_action = CustomAction(\n",
    "    tool=\"dummy tool\",\n",
    "    tool_input=\"dummy input\",\n",
    "    tool_inputs={\"input\": \"real inputs\"},\n",
    "    log=\"dummy log\",\n",
    ")\n",
    "# and that pydantic doesn't complain about the corresponding StepOutput\n",
    "dummy_output = StepOutput.construct(decision=dummy_action, observation=\"foo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be410766",
   "metadata": {},
   "source": [
    "Now, let's subclass `ZeroShotAgent` to produce this `CustomAction` as output during the planning phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47ba88c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Optional, Any, Tuple\n",
    "\n",
    "from langchain.agents.mrkl.base import ZeroShotAgent\n",
    "from langchain.agents.mrkl.prompt import PREFIX\n",
    "from langchain.agents.agent import Agent\n",
    "from langchain.agents.memory import BaseAgentMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "PREFIX = \"\"\"Finish the following task as best you can. You have access to the following tools:\"\"\"\n",
    "\n",
    "FORMAT_INSTRUCTIONS = \"\"\"\n",
    "Use the following format:\n",
    "\n",
    "Task: the task you must complete\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take; should be one of [{tool_names}].\n",
    "<Action Inputs>: the inputs to the action, enclosed by quotes\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Inputs/Observation can repeat N times)\n",
    "Thought: I am now finished with the task\n",
    "Action: Finished\n",
    "\"\"\".strip()\n",
    "\n",
    "SUFFIX = \"\"\"Begin!\n",
    "\n",
    "Task: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "\n",
    "class CustomAgent(ZeroShotAgent):\n",
    "    tools: Dict[str, Tool] = {}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_llm_and_tools(\n",
    "        cls,\n",
    "        tools: List[Tool],\n",
    "        **kwargs: Any,\n",
    "    ) -> Agent:\n",
    "        custom_agent = super().from_llm_and_tools(tools=tools, **kwargs)\n",
    "        custom_agent.tools = {tool.name: tool for tool in tools}\n",
    "        return custom_agent\n",
    "    \n",
    "    @property\n",
    "    def llm_prefix(self) -> str:\n",
    "        return \"\"\n",
    "    \n",
    "    @property\n",
    "    def finish_tool_name(self) -> str:\n",
    "        \"\"\"Name of the tool to use to finish the chain.\"\"\"\n",
    "        return \"Finished\"\n",
    "    \n",
    "    def get_full_inputs(\n",
    "        self, intermediate_steps: List[Tuple[AgentAction, str]], **kwargs: Any\n",
    "    ) -> Dict[str, Any]:\n",
    "        # like ZeroShotAgent.get_full_inputs, but with no stop\n",
    "        thoughts = self._construct_scratchpad(intermediate_steps)\n",
    "        new_inputs = {\"agent_scratchpad\": thoughts}\n",
    "        full_inputs = {**kwargs, **new_inputs}\n",
    "        return full_inputs\n",
    "\n",
    "    def _get_next_action(self, full_inputs: Dict[str, str]) -> AgentAction:\n",
    "        prefix = self.llm_chain.prompt.format(**full_inputs)\n",
    "        #print(prefix)\n",
    "        thought_and_tool_chain = GetMultipleOutputsChain(\n",
    "            llm=self.llm_chain.llm,\n",
    "            prefix=prefix,\n",
    "            variables=OrderedDict(\n",
    "                thought=\"Thought\",\n",
    "                action=\"Action\",\n",
    "            )\n",
    "        )\n",
    "        thought_and_tool = thought_and_tool_chain({})\n",
    "        #print(thought_and_tool)\n",
    "        tool = self.tools[thought_and_tool[\"action\"].strip()]\n",
    "        log = \"Thought: \" + thought_and_tool_chain.log()\n",
    "\n",
    "        if len(tool.variable_configs) == 0:\n",
    "            tool_inputs = {}\n",
    "        else:\n",
    "            tool_inputs_chain = GetMultipleOutputsChain(\n",
    "                llm=self.llm_chain.llm,\n",
    "                prefix=prefix + log,\n",
    "                variable_configs=tool.variable_configs,\n",
    "            )\n",
    "            tool_inputs = tool_inputs_chain({})\n",
    "            #print(tool_inputs)\n",
    "            log += \"\\n\" + tool.variable_configs[0].prompt + \": \" + tool_inputs_chain.log()\n",
    "\n",
    "        return CustomAction(\n",
    "            tool=tool.name,\n",
    "            tool_input=\"dummy\",\n",
    "            tool_inputs=tool_inputs,\n",
    "            log=log,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff933e7",
   "metadata": {},
   "source": [
    "And we subclass `AgentExecutor` to use our custom tools with this `CustomAction` as input during the observation feedback loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7504b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AgentFinish\n",
    "from langchain.agents.agent import Agent, AgentExecutor\n",
    "from langchain.agents.step import StepOutput\n",
    "\n",
    "\n",
    "class CustomAgentExecutor(AgentExecutor):\n",
    "    def _take_next_step(self, memory: BaseAgentMemory) -> StepOutput:\n",
    "        \"\"\"Take a single step in the thought-action-observation loop.\n",
    "\n",
    "        Override this to take control of how the agent makes and acts on choices.\n",
    "        \"\"\"\n",
    "        # Call the LLM to see what to do.\n",
    "        output = self.agent.plan_structured(memory)\n",
    "        # If the tool chosen is the finishing tool, then we end and return.\n",
    "        if isinstance(output, AgentFinish):\n",
    "            return StepOutput(decision=output)\n",
    "        tool = self.name_to_tool_map[output.tool]\n",
    "        self.callback_manager.on_tool_start(\n",
    "            {\"name\": str(tool.func)[:60] + \"...\"},\n",
    "            output,\n",
    "            color=\"green\",\n",
    "            verbose=self.verbose,\n",
    "        )\n",
    "        observation = tool.func(**output.tool_inputs)\n",
    "        color = self.color_mapping[output.tool]\n",
    "        self.callback_manager.on_tool_end(\n",
    "            observation,\n",
    "            color=color,\n",
    "            observation_prefix=self.agent.observation_prefix,\n",
    "            llm_prefix=self.agent.llm_prefix,\n",
    "            verbose=self.verbose,\n",
    "        )\n",
    "        # .construct because pydantic doesn't like us subclassing AgentAction\n",
    "        return StepOutput.construct(decision=output, observation=observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af38626",
   "metadata": {},
   "source": [
    "Let's try running it now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc81fd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new CustomAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to read the contents of the file and add the shebang line if it is not already present.\n",
      "Action:  Read File\n",
      "File to read: \"script.py\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFile contents are:\n",
      "\n",
      "```\n",
      "words = [\"Hello\", \"World!\"]\n",
      "print(\" \".join(words))\n",
      "```\n",
      "\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to check if the shebang line is present\n",
      "Action:  Read File\n",
      "File to read: \"script.py\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFile contents are:\n",
      "\n",
      "```\n",
      "words = [\"Hello\", \"World!\"]\n",
      "print(\" \".join(words))\n",
      "```\n",
      "\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The shebang line is not present, so I need to add it\n",
      "Action:  Write File\n",
      "File to write: \"script.py\"\n",
      "File contents: ```\n",
      "#!/usr/bin/env python3\n",
      "words = [\"Hello\", \"World!\"]\n",
      "print(\" \".join(words))\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mFile written successfully\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I am now finished with the task\n",
      "Action:  Finished\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dummy'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tools = [read_tool, write_tool, finished_tool]\n",
    "\n",
    "custom_agent = CustomAgent.from_llm_and_tools(\n",
    "    llm=llm,\n",
    "    tools=custom_tools,\n",
    "    prefix=PREFIX,\n",
    "    format_instructions=FORMAT_INSTRUCTIONS,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "custom_executor = CustomAgentExecutor.from_agent_and_tools(\n",
    "    agent=custom_agent,\n",
    "    tools=custom_tools,\n",
    "    max_iterations=4,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "custom_executor.run(\n",
    "    \"Ensure the file `script.py` has the shebang line \\\"#!/usr/bin/env python3\\\" at the top.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22e62eb",
   "metadata": {},
   "source": [
    "Note that because we're reading from a file, the contents of the file are unpredictable, and therefore it can be hard to write a regex that reliably parses the output. The usage of `VariableConfig` in `GetMultipleOutputsChain` allows you to experiment with different prompting styles and stops for each variable without requiring you to write and modify a parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdfd8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1677b440931f40d89ef8be7bf03acb108ce003de0ac9b18e8d43753ea2e7103"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
